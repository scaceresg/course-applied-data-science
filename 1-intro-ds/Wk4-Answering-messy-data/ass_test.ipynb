{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "#RUN FIRST, installs a missing library\n",
    "import sys\n",
    "!{sys.executable} -m pip install lxml==4.4.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy.stats as stats\n",
    "import re\n",
    "\n",
    "def nhl_correlation():\n",
    "    \n",
    "    nhl_df = pd.read_csv('../assignments/assignment4/assets/nhl.csv')\n",
    "    cities=pd.read_html(\"../assignments/assignment4/assets/wikipedia_data.html\")[1]\n",
    "    cities=cities.iloc[:-1,[0,3,5,6,7,8]]\n",
    "    \n",
    "    # Clean nhl df\n",
    "    def clean_nhl_df():\n",
    "\n",
    "        # Select data from 2018 only\n",
    "        nhl_df = nhl_df[nhl_df['year']==2018]\n",
    "\n",
    "        nhl_df.drop(labels=[0, 9, 18, 26], inplace=True)\n",
    "\n",
    "        # Eliminate * at the end of the team name\n",
    "        def fix_team_name(row):\n",
    "            pattern = '.+?\\*'\n",
    "            if bool(re.search(pattern, row['team'])):\n",
    "                row['team'] = re.sub('\\*', '', row['team']).strip()\n",
    "\n",
    "            return row\n",
    "\n",
    "        nhl_df = nhl_df.apply(lambda x: fix_team_name(x), axis='columns')\n",
    "\n",
    "        # Get metropolitan area per team\n",
    "        def get_metro_area(team):\n",
    "            metropolitan_areas = {'New York City': ['New York Islanders', 'New York Rangers', 'New Jersey Devils'],\n",
    "                                  'Los Angeles': ['Los Angeles Kings', 'Anaheim Ducks'],\n",
    "                                  'San Francisco Bay Area': ['San Jose Sharks'],\n",
    "                                  'Chicago': ['Chicago Blackhawks'],\n",
    "                                  'Dallas–Fort Worth': ['Dallas Stars'],\n",
    "                                  'Washington, D.C.': ['Washington Capitals'],\n",
    "                                  'Philadelphia': ['Philadelphia Flyers'],\n",
    "                                  'Boston': ['Boston Bruins'],\n",
    "                                  'Minneapolis–Saint Paul': ['Minnesota Wild'],\n",
    "                                  'Denver': ['Colorado Avalanche'],\n",
    "                                  'Miami–Fort Lauderdale': ['Florida Panthers'],\n",
    "                                  'Phoenix': ['Arizona Coyotes'],\n",
    "                                  'Detroit': ['Detroit Red Wings'],\n",
    "                                  'Toronto': ['Toronto Maple Leafs'],\n",
    "                                  'Tampa Bay Area': ['Tampa Bay Lightning'],\n",
    "                                  'Pittsburgh': ['Pittsburgh Penguins'],\n",
    "                                  'St. Louis': ['St. Louis Blues'],\n",
    "                                  'Nashville': ['Nashville Predators'],\n",
    "                                  'Buffalo': ['Buffalo Sabres'],\n",
    "                                  'Montreal': ['Montreal Canadiens'],\n",
    "                                  'Vancouver': ['Vancouver Canucks'],\n",
    "                                  'Columbus': ['Columbus Blue Jackets'],\n",
    "                                  'Calgary': ['Calgary Flames'],\n",
    "                                  'Ottawa': ['Ottawa Senators'],\n",
    "                                  'Edmonton': ['Edmonton Oilers'],\n",
    "                                  'Winnipeg': ['Winnipeg Jets'],\n",
    "                                  'Las Vegas': ['Vegas Golden Knights'],\n",
    "                                  'Raleigh': ['Carolina Hurricanes']}\n",
    "\n",
    "            for m_area in metropolitan_areas:\n",
    "                if team in metropolitan_areas[m_area]:\n",
    "                    return m_area\n",
    "\n",
    "        nhl_df['Metropolitan area'] = nhl_df['team'].apply(lambda x: get_metro_area(x))\n",
    "\n",
    "        nhl_df = nhl_df.astype({'W': 'int64', 'L': 'int64'})\n",
    "\n",
    "        return nhl_df\n",
    "\n",
    "    # Adjust cities df and set Metro Areas as index\n",
    "    def clean_cities_df():\n",
    "\n",
    "        # Rename Population column\n",
    "        cities.rename(columns={'Population (2016 est.)[8]': 'Population'}, inplace=True)\n",
    "\n",
    "        # Change dtype for Population\n",
    "        cities = cities.astype({'Population': 'int64'})\n",
    "\n",
    "        cities.set_index('Metropolitan area', inplace=True)\n",
    "\n",
    "        return cities['Population']\n",
    "    \n",
    "    # Clean nhl df\n",
    "    nhl_df = clean_nhl_df()\n",
    "    \n",
    "    # Group by Metropolitan area\n",
    "    nhl_groups = nhl_df.groupby('Metropolitan area').agg({'W': np.nansum, 'L': np.nansum})\n",
    "    nhl_groups['Win/Loss ratio'] = nhl_df['W']/(nhl_df['W'] + nhl_df['L'])\n",
    "    \n",
    "    # Adjust cities df and set Metro Areas as index\n",
    "    cities = clean_cities_df()\n",
    "    \n",
    "    # Join nhl and cities dfs\n",
    "    resulting_df = pd.merge(left=cities, right=nhl_groups, how='inner', left_index=True, right_index=True)\n",
    "    \n",
    "    # raise NotImplementedError()\n",
    "    \n",
    "    population_by_region = resulting_df['Population'].to_list() # pass in metropolitan area population from cities\n",
    "    win_loss_by_region = resulting_df['Win/Loss ratio'].to_list() # pass in win/loss ratio from nhl_df in the same order as cities[\"Metropolitan area\"]\n",
    "\n",
    "    assert len(population_by_region) == len(win_loss_by_region), \"Q1: Your lists must be the same length\"\n",
    "    assert len(population_by_region) == 28, \"Q1: There should be 28 teams being analysed for NHL\"\n",
    "    \n",
    "    return stats.pearsonr(population_by_region, win_loss_by_region)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "lxml not found, please install it",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[39mprint\u001b[39m(nhl_correlation())\n",
      "Cell \u001b[1;32mIn[8], line 9\u001b[0m, in \u001b[0;36mnhl_correlation\u001b[1;34m()\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mnhl_correlation\u001b[39m():\n\u001b[0;32m      8\u001b[0m     nhl_df \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mread_csv(\u001b[39m'\u001b[39m\u001b[39m../assignments/assignment4/assets/nhl.csv\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m----> 9\u001b[0m     cities\u001b[39m=\u001b[39mpd\u001b[39m.\u001b[39;49mread_html(\u001b[39m\"\u001b[39;49m\u001b[39m../assignments/assignment4/assets/wikipedia_data.html\u001b[39;49m\u001b[39m\"\u001b[39;49m)[\u001b[39m1\u001b[39m]\n\u001b[0;32m     10\u001b[0m     cities\u001b[39m=\u001b[39mcities\u001b[39m.\u001b[39miloc[:\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m,[\u001b[39m0\u001b[39m,\u001b[39m3\u001b[39m,\u001b[39m5\u001b[39m,\u001b[39m6\u001b[39m,\u001b[39m7\u001b[39m,\u001b[39m8\u001b[39m]]\n\u001b[0;32m     12\u001b[0m     \u001b[39m# Clean nhl df\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\SebastianCaceresG\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\util\\_decorators.py:331\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    325\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(args) \u001b[39m>\u001b[39m num_allow_args:\n\u001b[0;32m    326\u001b[0m     warnings\u001b[39m.\u001b[39mwarn(\n\u001b[0;32m    327\u001b[0m         msg\u001b[39m.\u001b[39mformat(arguments\u001b[39m=\u001b[39m_format_argument_list(allow_args)),\n\u001b[0;32m    328\u001b[0m         \u001b[39mFutureWarning\u001b[39;00m,\n\u001b[0;32m    329\u001b[0m         stacklevel\u001b[39m=\u001b[39mfind_stack_level(),\n\u001b[0;32m    330\u001b[0m     )\n\u001b[1;32m--> 331\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\SebastianCaceresG\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\io\\html.py:1205\u001b[0m, in \u001b[0;36mread_html\u001b[1;34m(io, match, flavor, header, index_col, skiprows, attrs, parse_dates, thousands, encoding, decimal, converters, na_values, keep_default_na, displayed_only, extract_links)\u001b[0m\n\u001b[0;32m   1201\u001b[0m validate_header_arg(header)\n\u001b[0;32m   1203\u001b[0m io \u001b[39m=\u001b[39m stringify_path(io)\n\u001b[1;32m-> 1205\u001b[0m \u001b[39mreturn\u001b[39;00m _parse(\n\u001b[0;32m   1206\u001b[0m     flavor\u001b[39m=\u001b[39;49mflavor,\n\u001b[0;32m   1207\u001b[0m     io\u001b[39m=\u001b[39;49mio,\n\u001b[0;32m   1208\u001b[0m     match\u001b[39m=\u001b[39;49mmatch,\n\u001b[0;32m   1209\u001b[0m     header\u001b[39m=\u001b[39;49mheader,\n\u001b[0;32m   1210\u001b[0m     index_col\u001b[39m=\u001b[39;49mindex_col,\n\u001b[0;32m   1211\u001b[0m     skiprows\u001b[39m=\u001b[39;49mskiprows,\n\u001b[0;32m   1212\u001b[0m     parse_dates\u001b[39m=\u001b[39;49mparse_dates,\n\u001b[0;32m   1213\u001b[0m     thousands\u001b[39m=\u001b[39;49mthousands,\n\u001b[0;32m   1214\u001b[0m     attrs\u001b[39m=\u001b[39;49mattrs,\n\u001b[0;32m   1215\u001b[0m     encoding\u001b[39m=\u001b[39;49mencoding,\n\u001b[0;32m   1216\u001b[0m     decimal\u001b[39m=\u001b[39;49mdecimal,\n\u001b[0;32m   1217\u001b[0m     converters\u001b[39m=\u001b[39;49mconverters,\n\u001b[0;32m   1218\u001b[0m     na_values\u001b[39m=\u001b[39;49mna_values,\n\u001b[0;32m   1219\u001b[0m     keep_default_na\u001b[39m=\u001b[39;49mkeep_default_na,\n\u001b[0;32m   1220\u001b[0m     displayed_only\u001b[39m=\u001b[39;49mdisplayed_only,\n\u001b[0;32m   1221\u001b[0m     extract_links\u001b[39m=\u001b[39;49mextract_links,\n\u001b[0;32m   1222\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\SebastianCaceresG\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\io\\html.py:982\u001b[0m, in \u001b[0;36m_parse\u001b[1;34m(flavor, io, match, attrs, encoding, displayed_only, extract_links, **kwargs)\u001b[0m\n\u001b[0;32m    980\u001b[0m retained \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m    981\u001b[0m \u001b[39mfor\u001b[39;00m flav \u001b[39min\u001b[39;00m flavor:\n\u001b[1;32m--> 982\u001b[0m     parser \u001b[39m=\u001b[39m _parser_dispatch(flav)\n\u001b[0;32m    983\u001b[0m     p \u001b[39m=\u001b[39m parser(io, compiled_match, attrs, encoding, displayed_only, extract_links)\n\u001b[0;32m    985\u001b[0m     \u001b[39mtry\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\SebastianCaceresG\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\io\\html.py:939\u001b[0m, in \u001b[0;36m_parser_dispatch\u001b[1;34m(flavor)\u001b[0m\n\u001b[0;32m    937\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    938\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m _HAS_LXML:\n\u001b[1;32m--> 939\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mImportError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mlxml not found, please install it\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m    940\u001b[0m \u001b[39mreturn\u001b[39;00m _valid_parsers[flavor]\n",
      "\u001b[1;31mImportError\u001b[0m: lxml not found, please install it"
     ]
    }
   ],
   "source": [
    "print(nhl_correlation())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install lxml"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
